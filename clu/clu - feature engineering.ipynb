{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall do\n",
    "\n",
    "- \\# of sentiment words by group\n",
    "- \\# of unique / \\# of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('we', 'PRP'), ('are', 'VBP'), ('out', 'RP'), ('here', 'RB')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag([\"we\", \"are\", \"out\", \"here\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrcsentiment = pd.read_csv(\"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\", sep = \"\\t\", header = None)\n",
    "nrcsentiment.columns = [\"word\", \"sentiment\", \"indicator\"]\n",
    "nrcsentiment = nrcsentiment[nrcsentiment.indicator == 1][[\"word\", \"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"beer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    punct = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\t)\")\n",
    "    text = text.lower()\n",
    "    return word_tokenize(re.sub(punct, \" \", text))\n",
    " \n",
    "def unique_over_total(text):\n",
    "    numunique = len(np.unique(text))\n",
    "    return numunique / len(text)\n",
    "\n",
    "def tidy_text(df):\n",
    "    \"\"\"Takes our df and makes it into tidy data wrt text:\n",
    "    id, word\n",
    "    id, word etc...\n",
    "    \"\"\"\n",
    "    identifier = df[\"index\"]\n",
    "    words = {\"index\": [], \"word\": [], \"part_of_speech\": []}\n",
    "    uniquefeature = []\n",
    "    \n",
    "    for i in identifier:\n",
    "        texttosplit = list(df[df[\"index\"] == i][\"review/text\"])[0]\n",
    "        cleaned = cleaner(texttosplit)\n",
    "        \n",
    "        uniquefeature.append(unique_over_total(cleaned))\n",
    "        \n",
    "        for j in np.unique(cleaned):\n",
    "            words[\"index\"].append(i)\n",
    "            words[\"word\"].append(j)\n",
    "            words[\"part_of_speech\"].append(pos_tag([j])[0][1])\n",
    "        \n",
    "    untidydf = pd.DataFrame({\"index\": identifier, \"proportion_unique\": uniquefeature})\n",
    "    tidydf = pd.DataFrame({\"index\": words[\"index\"], \"word\": words[\"word\"], \"part_of_speech\": words[\"part_of_speech\"]})\n",
    "    \n",
    "    return untidydf, tidydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics, tidydata = tidy_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>proportion_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40163</td>\n",
       "      <td>0.744681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8135</td>\n",
       "      <td>0.660194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10529</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44610</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37062</td>\n",
       "      <td>0.747368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  proportion_unique\n",
       "0  40163           0.744681\n",
       "1   8135           0.660194\n",
       "2  10529           0.850746\n",
       "3  44610           0.814286\n",
       "4  37062           0.747368"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40163</td>\n",
       "      <td>DT</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40163</td>\n",
       "      <td>NN</td>\n",
       "      <td>absinthe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40163</td>\n",
       "      <td>VBD</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40163</td>\n",
       "      <td>IN</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40163</td>\n",
       "      <td>NN</td>\n",
       "      <td>aftertaste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index part_of_speech        word\n",
       "0  40163             DT           a\n",
       "1  40163             NN    absinthe\n",
       "2  40163            VBD       added\n",
       "3  40163             IN       after\n",
       "4  40163             NN  aftertaste"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abacus</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>abandon</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>abandon</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>abandon</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word sentiment\n",
       "19     abacus     trust\n",
       "23    abandon      fear\n",
       "25    abandon  negative\n",
       "27    abandon   sadness\n",
       "30  abandoned     anger"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrcsentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentimenttidy = tidydata[[\"index\", \"word\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentimentjoined = pd.merge(sentimenttidy, nrcsentiment, on = \"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentimentjoined = pd.get_dummies(sentimentjoined, columns = [\"sentiment\"])\n",
    "groupcols = ['sentiment_anger', 'sentiment_anticipation',\n",
    "             'sentiment_disgust', 'sentiment_fear', 'sentiment_joy',\n",
    "             'sentiment_negative', 'sentiment_positive', 'sentiment_sadness',\n",
    "             'sentiment_surprise', 'sentiment_trust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalsentiment = sentimentjoined.groupby([\"index\"])[groupcols].sum()\n",
    "finalsentiment[\"index\"] = finalsentiment.index\n",
    "finalsentiment.reset_index(drop = True, inplace = True)\n",
    "summedsentiments = finalsentiment[groupcols].sum(axis = 1)\n",
    "\n",
    "\n",
    "for i in groupcols:\n",
    "    finalsentiment[i] = finalsentiment[i] / summedsentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentfinal = pd.merge(pd.merge(finalsentiment, metrics, on = \"index\"), df, on = \"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['part_of_speech'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-f79656b5f55d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtidydata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtidydata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"part_of_speech\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m groupcols_pos = [\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m'part_of_speech_#'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'part_of_speech_$'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m'part_of_speech_'\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'part_of_speech_('\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'part_of_speech_)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m'part_of_speech_:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'part_of_speech_CC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'part_of_speech_CD'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sam\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[0mwith_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[0mwith_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns_to_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns_to_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix_sep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sam\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[0;32m   2048\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2049\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2050\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2051\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2052\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sam\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   3573\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3574\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[1;32m-> 3575\u001b[1;33m                                  labels[mask])\n\u001b[0m\u001b[0;32m   3576\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3577\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: labels ['part_of_speech'] not contained in axis"
     ]
    }
   ],
   "source": [
    "tidydata = pd.get_dummies(tidydata, columns = [\"part_of_speech\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groupcols_pos = [\n",
    "    'part_of_speech_#', 'part_of_speech_$',\n",
    "    'part_of_speech_\\'\\'', 'part_of_speech_(', 'part_of_speech_)',\n",
    "    'part_of_speech_:', 'part_of_speech_CC', 'part_of_speech_CD',\n",
    "    'part_of_speech_DT', 'part_of_speech_IN', 'part_of_speech_JJ',\n",
    "    'part_of_speech_JJR', 'part_of_speech_JJS', 'part_of_speech_LS',\n",
    "    'part_of_speech_MD', 'part_of_speech_NN', 'part_of_speech_NNS',\n",
    "    'part_of_speech_POS', 'part_of_speech_PRP', 'part_of_speech_PRP$',\n",
    "    'part_of_speech_RB', 'part_of_speech_RBR', 'part_of_speech_TO',\n",
    "    'part_of_speech_VB', 'part_of_speech_VBD', 'part_of_speech_VBG',\n",
    "    'part_of_speech_VBN', 'part_of_speech_VBP', 'part_of_speech_VBZ',\n",
    "    'part_of_speech_WDT', 'part_of_speech_WP', 'part_of_speech_WP$',\n",
    "    'part_of_speech_WRB', 'part_of_speech_``'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'word', 'part_of_speech_#', 'part_of_speech_$',\n",
       "       'part_of_speech_''', 'part_of_speech_(', 'part_of_speech_)',\n",
       "       'part_of_speech_:', 'part_of_speech_CC', 'part_of_speech_CD',\n",
       "       'part_of_speech_DT', 'part_of_speech_IN', 'part_of_speech_JJ',\n",
       "       'part_of_speech_JJR', 'part_of_speech_JJS', 'part_of_speech_LS',\n",
       "       'part_of_speech_MD', 'part_of_speech_NN', 'part_of_speech_NNS',\n",
       "       'part_of_speech_POS', 'part_of_speech_PRP', 'part_of_speech_PRP$',\n",
       "       'part_of_speech_RB', 'part_of_speech_RBR', 'part_of_speech_TO',\n",
       "       'part_of_speech_VB', 'part_of_speech_VBD', 'part_of_speech_VBG',\n",
       "       'part_of_speech_VBN', 'part_of_speech_VBP', 'part_of_speech_VBZ',\n",
       "       'part_of_speech_WDT', 'part_of_speech_WP', 'part_of_speech_WP$',\n",
       "       'part_of_speech_WRB', 'part_of_speech_``'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidydata.head().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalpos = tidydata.groupby([\"index\"])[groupcols_pos].sum()\n",
    "finalpos[\"index\"] = finalpos.index\n",
    "finalpos.reset_index(drop = True, inplace = True)\n",
    "summedpos = finalpos[groupcols_pos].sum(axis = 1)\n",
    "\n",
    "for i in groupcols_pos:\n",
    "    finalpos[i] = finalpos[i] / summedpos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_of_speech_#</th>\n",
       "      <th>part_of_speech_$</th>\n",
       "      <th>part_of_speech_''</th>\n",
       "      <th>part_of_speech_(</th>\n",
       "      <th>part_of_speech_)</th>\n",
       "      <th>part_of_speech_:</th>\n",
       "      <th>part_of_speech_CC</th>\n",
       "      <th>part_of_speech_CD</th>\n",
       "      <th>part_of_speech_DT</th>\n",
       "      <th>part_of_speech_IN</th>\n",
       "      <th>...</th>\n",
       "      <th>part_of_speech_VBG</th>\n",
       "      <th>part_of_speech_VBN</th>\n",
       "      <th>part_of_speech_VBP</th>\n",
       "      <th>part_of_speech_VBZ</th>\n",
       "      <th>part_of_speech_WDT</th>\n",
       "      <th>part_of_speech_WP</th>\n",
       "      <th>part_of_speech_WP$</th>\n",
       "      <th>part_of_speech_WRB</th>\n",
       "      <th>part_of_speech_``</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   part_of_speech_#  part_of_speech_$  part_of_speech_''  part_of_speech_(  \\\n",
       "0               0.0               0.0                0.0               0.0   \n",
       "1               0.0               0.0                0.0               0.0   \n",
       "2               0.0               0.0                0.0               0.0   \n",
       "3               0.0               0.0                0.0               0.0   \n",
       "4               0.0               0.0                0.0               0.0   \n",
       "\n",
       "   part_of_speech_)  part_of_speech_:  part_of_speech_CC  part_of_speech_CD  \\\n",
       "0               0.0               0.0           0.057143                0.0   \n",
       "1               0.0               0.0           0.054054                0.0   \n",
       "2               0.0               0.0           0.042553                0.0   \n",
       "3               0.0               0.0           0.046512                0.0   \n",
       "4               0.0               0.0           0.008000                0.0   \n",
       "\n",
       "   part_of_speech_DT  part_of_speech_IN  ...    part_of_speech_VBG  \\\n",
       "0           0.085714           0.142857  ...              0.028571   \n",
       "1           0.054054           0.081081  ...              0.000000   \n",
       "2           0.106383           0.085106  ...              0.000000   \n",
       "3           0.069767           0.093023  ...              0.000000   \n",
       "4           0.056000           0.064000  ...              0.032000   \n",
       "\n",
       "   part_of_speech_VBN  part_of_speech_VBP  part_of_speech_VBZ  \\\n",
       "0               0.000               0.000            0.000000   \n",
       "1               0.000               0.000            0.000000   \n",
       "2               0.000               0.000            0.021277   \n",
       "3               0.000               0.000            0.023256   \n",
       "4               0.016               0.008            0.008000   \n",
       "\n",
       "   part_of_speech_WDT  part_of_speech_WP  part_of_speech_WP$  \\\n",
       "0               0.000                0.0                 0.0   \n",
       "1               0.000                0.0                 0.0   \n",
       "2               0.000                0.0                 0.0   \n",
       "3               0.000                0.0                 0.0   \n",
       "4               0.008                0.0                 0.0   \n",
       "\n",
       "   part_of_speech_WRB  part_of_speech_``  index  \n",
       "0                 0.0                0.0      0  \n",
       "1                 0.0                0.0      1  \n",
       "2                 0.0                0.0      2  \n",
       "3                 0.0                0.0      3  \n",
       "4                 0.0                0.0      4  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalpos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finaldf = pd.merge(finalpos, sentfinal, on = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = groupcols_pos + groupcols + [\"proportion_unique\", \"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finaldf = finaldf[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finaldf.to_csv(\"more_features.csv\", encoding = \"utf-8\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
